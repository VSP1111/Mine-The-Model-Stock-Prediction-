{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":62583,"databundleVersionId":6927485,"sourceType":"competition"}],"dockerImageVersionId":30588,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport io\n%matplotlib inline","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def lstm_model1(path):\n     df = pd.read_csv(path)\n     df1 = df.reset_index()['Close']\n     from sklearn.preprocessing import MinMaxScaler\n     scaler = MinMaxScaler(feature_range = (0,1))\n     df1 = scaler.fit_transform(np.array(df1).reshape(-1,1))\n     training_size =  2400\n     test_size = 600\n     train_data , test_data = df1[0:training_size,:],df1[training_size :, :1]\n     def create_dataset(dataset , time_step = 250):\n       dataX , dataY = [] , []\n       for j in range(len(dataset)-time_step-1):\n         a= dataset[j:(j+time_step),0]\n         dataX.append(a)\n         dataY.append(dataset[j + time_step , 0])\n       return np.array(dataX), np.array(dataY)\n     time_step = 250\n     X_train , y_train = create_dataset(train_data , time_step)\n     X_test , y_test = create_dataset(test_data , time_step)\n     X_train = X_train.reshape(X_train.shape[0],X_train.shape[1],1)\n     X_test = X_test.reshape(X_test.shape[0],X_test.shape[1],1)\n     import tensorflow as tf\n     from tensorflow.keras.models import Sequential\n     from tensorflow.keras.layers import Dense\n     from tensorflow.keras.layers import LSTM\n     model = Sequential()\n     model.add(LSTM(50,return_sequences = True,input_shape=(250,1)))\n     model.add(LSTM(50,return_sequences=True))\n     model.add(LSTM(50))\n     model.add(Dense(1))\n     model.compile(loss='mean_squared_error',optimizer = 'adam')\n     model.fit(X_train,y_train , validation_data=(X_test,y_test),epochs = 100 , batch_size=64,verbose = 1)\n     train_predict = model.predict(X_train)\n     test_predict = model.predict(X_test)\n     train_predict = scaler.inverse_transform(train_predict)\n     test_predict = scaler.inverse_transform(test_predict)\n     x_input = test_data[350:].reshape(1,-1)\n     temp_input = list(x_input)\n     lst_output = []\n     n_steps = 250\n     k=0\n     while(k<100):\n       if(len(temp_input)>250):\n         x_input = np.array(temp_input[1:])\n\n         x_input = x_input.reshape((1, n_steps , 1))\n         yhat = model.predict(x_input,verbose = 0)\n\n         temp_input.extend(yhat[0].tolist())\n         temp_input = temp_input[1:]\n         lst_output.extend(yhat.tolist())\n         k=k+1\n       else:\n         x_input = x_input.reshape((1,n_steps,1))\n         yhat = model.predict(x_input,verbose = 0)\n         \n         temp_input.extend(yhat[0].tolist())\n         lst_output.extend(yhat.tolist())\n         k = k +1\n     lst_output = scaler.inverse_transform(lst_output) \n     return lst_output\n     \n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dfs = []\npredicted_dataframe=[]\nfolder_path = '/kaggle/input/mine-the-model-2023/Upload-Dataset/TRAIN'\nfor filename in os.listdir(folder_path):\n  stock_df = os.path.join(folder_path,filename)\n  predicted_dataframe =lstm_model1(stock_df)\n  dfs.append(predicted_dataframe)\nx = []\nz = [0] * 5000\nm = []\nfor filename in os.listdir(folder_path):\n    a = filename[:3] + '_#' \n    for i in range(100):\n        y = a + str(i+1)\n        x.append(y)\nfor i in range(50):\n    for k in range(100):\n        u = 100*i + k\n        z[u]  = float(dfs[i][k])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cc = pd.DataFrame({'ID' : x , 'Price' : z})\ncc.to_csv('SubmissionVC.csv' ,index = False)\ncc","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}